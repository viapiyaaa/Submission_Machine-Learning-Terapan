# -*- coding: utf-8 -*-
"""Predictive Analytics: Klasifikasi Obesitas .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t7TuNgDHbGo2yeT2XfA4f61NgFjkgrZL

**Predictive Analytics: Klasifikasi Obesitas (Underweight, Normal, Overweight, Obese)**

---


**Evi Afiyatus Solihah - MC299D5X1752**

**Latar Belakang Proyek: Prediksi Tingkat Obesitas Menggunakan Machine Learning**

Obesitas merupakan masalah kesehatan global yang terus meningkat dan berkontribusi terhadap berbagai penyakit kronis seperti diabetes, hipertensi, dan penyakit jantung. Deteksi dan klasifikasi tingkat obesitas secara dini menjadi penting untuk mendukung pencegahan dan penanganan yang tepat. Dengan kemajuan teknologi, khususnya machine learning, kini analisis data kesehatan dapat dilakukan secara cepat dan akurat. Melalui pemanfaatan data seperti usia, jenis kelamin, indeks massa tubuh (IMT), dan aktivitas fisik, model machine learning mampu memprediksi kategori obesitas seseorang, seperti underweight, normal, overweight, atau obese.

Proyek ini bertujuan untuk membangun model prediktif berbasis machine learning yang mampu mengklasifikasikan tingkat obesitas seseorang secara otomatis. Berbagai algoritma klasifikasi digunakan dalam pengembangan model ini, antara lain Random Forest, K-Nearest Neighbors (KNN), dan Support Vector Machine (SVM). Selain itu, proyek ini juga mengevaluasi performa masing-masing model dalam konteks klasifikasi multi-kelas.

## Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import  OneHotEncoder
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score

"""## Load Dataset

Load dataset merupakan proses memasukkan data dari sumber eksternal seperti file CSV ke dalam lingkungan kerja seperti Google Colab. Data biasanya dimuat ke dalam bentuk DataFrame menggunakan pustaka pandas agar bisa digunakan untuk analisis, visualisasi, atau pelatihan model machine learning. Langkah ini dilakukan di awal agar seluruh data tersedia dan siap digunakan dalam proses selanjutnya.

**Informasi Dataset**

| **Field** | **Value** |
|---------- |-----------|
| **Title** |Obesity prediction           |
|**Source**| Kaggle                                                                    |
| **Maintainer**   | MrSimple07                                                  |
| **License**      | Other (specified in description)                                          |
| **Visibility**   | Publik                                                                    |
| **Tags**         | Health, Health Conditions |
| **Usability**    | 10.00
"""

# Import module yang disediakan google colab untuk kebutuhan upload file
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download kaggle dataset and unzip the file
# !cp kaggle.json ~/.kaggle/

# !chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d mrsimple07/obesity-prediction
!unzip obesity-prediction.zip

df_predict = pd.read_csv('obesity_data.csv')
df_predict

"""Pada dataset ini terdapat 7 kolom. yaitu:

*   **Age** : Merepresentasikan Usia
*   **Gender** : Jenis Kelamin
*   **Height** : Tinggi Badan
*   **Weight** : Berat Badan
*   **BMI** : Indeks Massa Tubuh, ukuran proporsi berat dan tinggi badan
*   **PhysicalActivityLevel** : Tingkat aktivitas fisik sehari-hari
*   **ObesityCategory** : Kategori obesitas (misal: Normal weight, Overweight, obese, Underweight)

## Exploratory Data Analysis - Deskripsi Variabel

Pada tahap ini dilakukan pengecekan missing value, outlier, dan data duplikat, sekaligus penanganannya.
"""

df_predict.info()

"""Berdasarkan hasil eksekusi method df.info(), terdapat 2 kolom bertipe data numerik integer, yaitu Age dan PhysicalActivityLevel. Selain itu, terdapat 2 kolom bertipe data objek, yaitu Gender dan ObesityCategory. Terakhir, ada 3 kolom bertipe data float64, yaitu Height, Weight, dan BMI."""

df_predict.describe()

df_predict.shape

"""Berdasarkan hasil eksekusi method df.shape, terdapat 1000 baris dan 7 kolom

## Exploratory Data Analysis Menangani Missing Value

Menghitung jumlah nilai yang hilang (missing values) di setiap kolom pada DataFrame df_predict
"""

df_predict.isnull().sum()

"""Menghitung Jumlah baris data yang duplikat di dalam DataFrame df_predict"""

df_predict.duplicated().sum()

"""Menghitung proporsi atau persentase masing-masing kategori dalam kolom ObesityCategory pada DataFrame df_predict."""

df_predict.ObesityCategory.value_counts(normalize=True)

"""Membuat boxplot untuk melihat distribusi dan outlier pada kolom Age."""

sns.boxplot(x=df_predict['Age'])

"""Membuat boxplot untuk melihat distribusi dan outlier pada kolom BMI."""

sns.boxplot(x=df_predict['BMI'])

"""Membuat boxplot untuk melihat distribusi dan outlier pada kolom Weight."""

sns.boxplot(x=df_predict['Weight'])

"""Membuat boxplot untuk melihat distribusi dan outlier pada kolom Height."""

sns.boxplot(x=df_predict['Height'])

"""Menghapus outliers yang ada pada dataset"""

# Ambil hanya kolom numerikal
numeric_cols = df_predict.select_dtypes(include='number').columns
# Hitung Q1, Q3, dan IQR hanya untuk kolom numerikal
Q1 = df_predict[numeric_cols].quantile(0.25)
Q3 = df_predict[numeric_cols].quantile(0.75)
IQR = Q3 - Q1
# Buat filter untuk menghapus baris yang mengandung outlier di kolom numerikal
filter_outliers = ~((df_predict[numeric_cols] < (Q1 - 1.5 * IQR)) |
                    (df_predict[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)
# Terapkan filter ke dataset asli (termasuk kolom non-numerikal)
df_predict = df_predict[filter_outliers]
# Cek ukuran dataset setelah outlier dihapus
df_predict.shape

"""Setelah outlier dihapus, dataset berisi 974 baris dan 7 kolom."""

mapping = {
    'Underweight': 1,
    'Normal weight': 2,
    'Overweight': 3,
    'Obese': 4
}

df_predict['ObesityCategory_num'] = df_predict['ObesityCategory'].map(mapping)

"""## Exploratory Data Analysis - Univariate Analysis

Mengelompokkan data menjadi numerik dan kategorikal.
"""

numerical_features = ['Age', 'Height', 'Weight', 'BMI', 'PhysicalActivityLevel', 'ObesityCategory_num']
categorical_features = ['Gender', 'ObesityCategory']

# Fitur Gender
feature = categorical_features[0]
count = df_predict[feature].value_counts()
percent = 100*df_predict[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

# Fitur ObesityCategory
feature = categorical_features[1]
count = df_predict[feature].value_counts()
percent = 100*df_predict[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

df_predict.hist(bins=50, figsize=(20,15))
plt.show()

"""## Exploratory Data Analysis - Multivariate Analysis"""

# Categorixal Features
sns.countplot(data=df_predict, x='Gender', hue='ObesityCategory')
plt.title("Jumlah Obesity Category berdasarkan Gender")
plt.show()

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df_predict, diag_kind = 'kde')

plt.figure(figsize=(10, 8))
correlation_matrix = df_predict[numerical_features].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Reduksi PCA dilakukan pada kolom Weight dan BMI karena keduanya memiliki nilai korelasi yang cukup tinggi, yang menunjukkan adanya hubungan erat antara kedua fitur tersebut."""

# Reduksi Dimensi dengan PCA
sns.pairplot(df_predict[['Weight','BMI']], plot_kws={"s": 3});

pca = PCA(n_components=2, random_state=123)
pca.fit(df_predict[['Weight','BMI']])
princ_comp = pca.transform(df_predict[['Weight','BMI']])

pca.explained_variance_ratio_.round(3)

pca = PCA(n_components=1, random_state=123)
pca.fit(df_predict[['Weight','BMI']])
df_predict['Weight_BMI_Combined'] = pca.transform(df_predict.loc[:, ('Weight','BMI')]).flatten()
df_predict.drop(['Weight','BMI'], axis=1, inplace=True)

df_predict.head()

"""## Data Preparation

Mengubah kategori ObesityCategory menjadi angka dan menyimpannya di kolom baru.
"""

mapping = {
    'Underweight': 1,
    'Normal weight': 2,
    'Overweight': 3,
    'Obese': 4
}

df_predict['ObesityCategory_num'] = df_predict['ObesityCategory'].map(mapping)

df_predict

"""Encoding Fitur Kategori Kolom Gender"""

df_predict = pd.concat([df_predict, pd.get_dummies(df_predict['Gender'], prefix='Gender')],axis=1)
df_predict.drop(['Gender'], axis=1, inplace=True)
df_predict.head()

"""Membagi data menjadi data latih dan data uji dengan rasio 90:10."""

# Train Test Split
X = df_predict.drop(["ObesityCategory"],axis =1)
y = df_predict["ObesityCategory"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

print(f'Total Dataset : {len(X)}')
print(f'Total Train Dataset: {len(X_train)}')
print(f'Total Test Dataset: {len(X_test)}')

# Standarsisasi
numerical_features = ['Age', 'Weight_BMI_Combined', 'PhysicalActivityLevel']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'SVM', 'LogisticRegression', 'GradientBoosting'])

"""## Random Forest"""

model_rf = RandomForestClassifier(max_depth= 20)
model_rf.fit(X_train, y_train)

# rf_pred = model_rf.predict(X_test)

"""## K-Nearest Neighbors"""

model_knn = KNeighborsClassifier(n_neighbors=5, weights='distance')
model_knn.fit(X_train, y_train)

# knn_pred = model_knn.predict(X_test)

"""## Support Vector Machine"""

model_svm = SVC()
model_svm.fit(X_train, y_train)

# svm_pred = model_svm.predict(X_test)

"""## Evaluasi Model"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

models = {
    'RandomForest': model_rf,
    'KNN': model_knn,
    'SVM': model_svm
}

predictions = {name: model.predict(X_test) for name, model in models.items()}

from sklearn.metrics import accuracy_score

accuracies = {name: accuracy_score(y_test, pred) for name, pred in predictions.items()}
accuracy_df = pd.DataFrame.from_dict(accuracies, orient='index', columns=['accuracy'])

print(accuracy_df)

accuracy_df.plot(kind='bar', legend=False)
plt.title('Accuracy of Classification Models')
plt.ylabel('Accuracy')
plt.xlabel('Model')
plt.ylim(0, 1)  # Karena accuracy antara 0-1
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

"""## Melakukan Prediksi"""

prediksi = X_test.iloc[:5].copy()
pred_dict = {'y_true': y_test.iloc[:5].values}  # label asli 5 baris

for name, model in models.items():
    pred = model.predict(prediksi)
    pred_dict['prediksi_' + name] = pred

result_df = pd.DataFrame(pred_dict)

print(result_df)